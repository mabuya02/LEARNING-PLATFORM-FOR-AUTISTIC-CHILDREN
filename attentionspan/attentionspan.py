# -*- coding: utf-8 -*-
"""AttentionSpan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nJIaZ6sVkoazBlbZie5c8HonD9dig2lH
"""

# Dependencies: pip install opencv-python dlib numpy

import os, sys, math, base64, bz2, pathlib, warnings, urllib.request
import cv2
import numpy as np
import dlib

warnings.filterwarnings("ignore", category=FutureWarning)

DLIB_MODEL = "shape_predictor_68_face_landmarks.dat"
DLIB_URL   = "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"

# --- Utils: model fetch if missing ---
def ensure_dlib_shape_predictor():
    if os.path.exists(DLIB_MODEL):
        return
    print("Downloading dlib 68-point predictor (~100MB) ...")
    import urllib.request
    bz2_path = DLIB_MODEL + ".bz2"
    urllib.request.urlretrieve(DLIB_URL, bz2_path)
    with bz2.open(bz2_path, "rb") as f_in, open(DLIB_MODEL, "wb") as f_out:
        f_out.write(f_in.read())
    os.remove(bz2_path)
    print("Model ready:", DLIB_MODEL)

ensure_dlib_shape_predictor()

# --- OpenCV webcam capture (local) ---
def take_photo(filename='photo.jpg', quality=0.9):
    """Capture a photo from webcam using OpenCV"""
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Error: Could not open webcam")
        return None
    
    print("Press SPACE to capture photo, ESC to exit")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Error: Failed to read from webcam")
            break
            
        # Display preview
        cv2.imshow('Webcam Preview - Press SPACE to capture, ESC to exit', frame)
        
        key = cv2.waitKey(1) & 0xFF
        if key == ord(' '):  # Space key
            cv2.imwrite(filename, frame)
            print(f"Photo saved as {filename}")
            break
        elif key == 27:  # ESC key
            print("Capture cancelled")
            cap.release()
            cv2.destroyAllWindows()
            return None
    
    cap.release()
    cv2.destroyAllWindows()
    return filename

# --- Vision helpers ---
def shape_to_np(shape, dtype="int"):
    coords = np.zeros((68, 2), dtype=dtype)
    for i in range(68):
        coords[i] = (shape.part(i).x, shape.part(i).y)
    return coords

def eye_aspect_ratio(eye_pts):
    # eye_pts: array shape (6,2) for landmarks [36..41] or [42..47]
    A = np.linalg.norm(eye_pts[1] - eye_pts[5])  # p2-p6
    B = np.linalg.norm(eye_pts[2] - eye_pts[4])  # p3-p5
    C = np.linalg.norm(eye_pts[0] - eye_pts[3])  # p1-p4
    if C == 0:
        return 0.0
    return (A + B) / (2.0 * C)

def angle_between_eyes(left_center, right_center):
    # returns absolute angle in degrees between eye centers (0° = perfectly horizontal)
    dx = right_center[0] - left_center[0]
    dy = right_center[1] - left_center[1]
    if dx == 0:
        return 90.0
    return abs(math.degrees(math.atan2(dy, dx)))

def draw_eye_poly(img, pts, color=(0,255,0)):
    pts = pts.astype(np.int32).reshape(-1,1,2)
    cv2.polylines(img, [pts], isClosed=True, color=color, thickness=1)

# --- Parameters (tune to your needs) ---
EAR_THRESH = 0.23     # Typical open-eye EAR ~0.25-0.3; closed < 0.2. Adjust per lighting/face.
ANGLE_MAX  = 20       # Max tilt (degrees) allowed to still count as "attentive".
CLAHE_CLIP = 3.0
TILE_GRID  = (8, 8)

# --- Load detectors / predictors ---
detector  = dlib.get_frontal_face_detector()   # HOG detector
predictor = dlib.shape_predictor(DLIB_MODEL)

# --- Capture a frame ---
print("Take a clear, front-facing photo with eyes open.")
print("Note: If webcam fails, the script will try to use test_image.jpg")

# Try webcam first, but handle graceful fallback
try:
    filename = take_photo('photo.jpg', quality=0.9)
    if filename is None:
        raise Exception("Webcam capture failed")
except:
    print("Webcam unavailable. Using test image instead.")
    filename = 'test_image.jpg'

img = cv2.imread(filename)
if img is None:
    print(f"Could not read image: {filename}")
    print("Make sure test_image.jpg exists or webcam is accessible")
    sys.exit(1)

print(f"Using image: {filename}")

# --- Preprocess ---
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP, tileGridSize=TILE_GRID)
gray = clahe.apply(gray)

# --- Detect faces (pick the largest) ---
faces = detector(gray, 1)
if len(faces) == 0:
    cv2.imshow('No Face Detected', img)
    print("No face detected. Try better lighting / framing.")
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    sys.exit(0)

# Choose the largest face by area
def rect_area(r): return (r.right()-r.left())*(r.bottom()-r.top())
faces = sorted(faces, key=rect_area, reverse=True)
face = faces[0]

# --- Landmarks & eyes ---
shape = predictor(gray, face)
landmarks = shape_to_np(shape)

left_eye_pts  = landmarks[36:42]  # 36..41
right_eye_pts = landmarks[42:48]  # 42..47

left_center  = np.mean(left_eye_pts, axis=0)
right_center = np.mean(right_eye_pts, axis=0)

left_ear  = eye_aspect_ratio(left_eye_pts)
right_ear = eye_aspect_ratio(right_eye_pts)
avg_ear   = (left_ear + right_ear) / 2.0

tilt_deg  = angle_between_eyes(left_center, right_center)

# --- Decide attentiveness ---
eyes_open      = avg_ear >= EAR_THRESH
head_forward   = tilt_deg <= ANGLE_MAX
attentive      = eyes_open and head_forward

# --- Draw overlays ---
(x, y, w, h) = (face.left(), face.top(), face.width(), face.height())
cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0) if attentive else (0, 0, 255), 2)

draw_eye_poly(img, left_eye_pts,  (0, 255, 0))
draw_eye_poly(img, right_eye_pts, (0, 255, 0))

cv2.circle(img, tuple(np.int32(left_center).astype(int)),  3, (0, 255, 255), -1)
cv2.circle(img, tuple(np.int32(right_center).astype(int)), 3, (0, 255, 255), -1)

label = f"Attentive: {attentive} | EAR: {avg_ear:.3f} (L {left_ear:.3f}, R {right_ear:.3f}) | Tilt: {tilt_deg:.1f}°"
cv2.putText(img, label, (max(5, x), max(20, y-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
            (0, 255, 0) if attentive else (0, 0, 255), 2, cv2.LINE_AA)

cv2.imshow('Attention Span Detection - Press any key to exit', img)
print(label)
print("Rule: attentive = (EAR >= {:.2f}) AND (tilt <= {}°)".format(EAR_THRESH, ANGLE_MAX))
cv2.waitKey(0)
cv2.destroyAllWindows()